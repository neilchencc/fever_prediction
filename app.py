import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
from sklearn.linear_model import LinearRegression
import joblib  # è¼‰å…¥ pkl æ¨¡å‹

# ---------------------------------------------------
# ğŸ“˜ Streamlit æ¨™é¡Œ
# ---------------------------------------------------
st.title("ğŸ“ˆ é«”æº«ç´€éŒ„åˆ†æå·¥å…·ï¼ˆCSV ä¸Šå‚³ + æ¨™æº–åŒ– + é æ¸¬ï¼‰")

# ---------------------------------------------------
# ğŸ“‚ ä¸Šå‚³ CSV æª”æ¡ˆ
# ---------------------------------------------------
uploaded_file = st.file_uploader("è«‹ä¸Šå‚³åŒ…å« Date, Time, BT æ¬„ä½çš„ CSV æª”æ¡ˆ", type=["csv"])

if uploaded_file is not None:
    # è®€å–ä¸¦æ¸…ç†æ¬„ä½åç¨±
    df = pd.read_csv(uploaded_file)
    df.columns = [c.strip() for c in df.columns]

    # å»ºç«‹ DateTime æ¬„ä½
    df["DateTime"] = df.apply(
        lambda row: datetime.strptime(str(int(row["Date"])) + f"{int(row['Time']):04d}", "%Y%m%d%H%M"),
        axis=1
    )
    df = df.sort_values("DateTime").reset_index(drop=True)

    st.write("### ğŸ§¾ åŸå§‹è³‡æ–™é è¦½ï¼š")
    st.dataframe(df)

    # ---------------------------------------------------
    # ğŸ§® è³‡æ–™æª¢æŸ¥èˆ‡æ™‚é–“ç¯„åœè¨­å®š
    # ---------------------------------------------------
    unique_dates = sorted(df["Date"].unique())
    if len(unique_dates) < 2:
        st.error("âš ï¸ è³‡æ–™ä¸è¶³ï¼Œè«‹è‡³å°‘åŒ…å«å…©å€‹ä¸åŒæ—¥æœŸã€‚")
    else:
        second_last_date = unique_dates[-2]
        last_date = unique_dates[-1]

        start_time = datetime.strptime(str(second_last_date) + "0800", "%Y%m%d%H%M")
        end_time = datetime.strptime(str(last_date) + "2359", "%Y%m%d%H%M")

        df_range = df[(df["DateTime"] >= start_time) & (df["DateTime"] <= end_time)]

        if df_range.empty:
            st.warning("âš ï¸ æ­¤æ™‚é–“å€é–“å…§æ²’æœ‰è³‡æ–™ã€‚")
        else:
            st.write(f"### â± åˆ†æç¯„åœï¼š{start_time} ï½ {end_time}")
            st.dataframe(df_range)

            # ---------------------------------------------------
            # ğŸ§© ç‰¹å¾µå·¥ç¨‹
            # ---------------------------------------------------
            t0 = df_range["DateTime"].min()
            df_range["Hours"] = (df_range["DateTime"] - t0).dt.total_seconds() / 3600

            max_bt = df_range["BT"].max()
            min_bt = df_range["BT"].min()
            mean_bt = df_range["BT"].mean()
            std_bt = df_range["BT"].std()

            X = df_range["Hours"].values.reshape(-1, 1)
            y = df_range["BT"].values
            model_lr = LinearRegression().fit(X, y)
            slope = model_lr.coef_[0]

            last_time = df_range["Hours"].max()
            last_8h = df_range[df_range["Hours"] >= last_time - 8]
            max_last8 = last_8h["BT"].max()

            range_bt = max_bt - min_bt
            diff_last8_allmax = max_last8 - max_bt

            # å»ºç«‹ç‰¹å¾µåˆ—è¡¨
            features = [max_bt, min_bt, mean_bt, std_bt, slope, range_bt, max_last8, diff_last8_allmax]
            feature_names = [
                "æœ€å¤§å€¼ (max)", "æœ€å°å€¼ (min)", "å¹³å‡å€¼ (mean)", "æ¨™æº–å·® (std)",
                "æ–œç‡ (slope)", "max - min", "æœ€å¾Œ8å°æ™‚çš„ max", "æœ€å¾Œ8å°æ™‚ max - å…¨éƒ¨ max"
            ]

            result_table = pd.DataFrame({
                "æŒ‡æ¨™": feature_names,
                "æ•¸å€¼": [f"{v:.4f}" for v in features]
            })
            st.subheader("ğŸ“Š çµ±è¨ˆçµæœ")
            st.table(result_table)

            # ---------------------------------------------------
            # ğŸ¤– æ¨¡å‹é æ¸¬
            # ---------------------------------------------------
            st.subheader("ğŸ¤– é æ¸¬çµæœ")

            try:
                # è¼‰å…¥ scaler èˆ‡ SVM æ¨¡å‹
                scaler = joblib.load("scaler.pkl")
                svm_model = joblib.load("svm_model.pkl")

                # æ¨™æº–åŒ–è¼¸å…¥ç‰¹å¾µ
                features_array = np.array(features).reshape(1, -1)
                features_scaled = scaler.transform(features_array)

                # æ¨¡å‹é æ¸¬
                if hasattr(svm_model, "predict_proba"):
                    pred_prob = svm_model.predict_proba(features_scaled)[0][1]
                else:
                    pred_prob = svm_model.decision_function(features_scaled)[0]

                threshold = 0.5
                if pred_prob >= threshold:
                    st.success(f"é æ¸¬çµæœï¼šæœªä¾†å¯èƒ½æœƒç™¼ç‡’ (åˆ†æ•¸/æ©Ÿç‡={pred_prob:.3f} â‰¥ {threshold})")
                else:
                    st.info(f"é æ¸¬çµæœï¼šæœªä¾†ä¸æœƒç™¼ç‡’ (åˆ†æ•¸/æ©Ÿç‡={pred_prob:.3f} < {threshold})")

            except FileNotFoundError as e:
                st.error(f"æ‰¾ä¸åˆ°å¿…è¦çš„æ¨¡å‹æª”æ¡ˆï¼š{e.filename}")
            except Exception as e:
                st.error(f"è¼‰å…¥æˆ–é æ¸¬æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

            # ---------------------------------------------------
            # ğŸ“‰ é«”æº«è®ŠåŒ–åœ–
            # ---------------------------------------------------
            st.subheader("ğŸ“‰ é«”æº«è®ŠåŒ–åœ–")
            st.line_chart(df_range.set_index("DateTime")["BT"])

else:
    st.info("â¬†ï¸ è«‹ä¸Šå‚³ä¸€å€‹ CSV æª”ä»¥é–‹å§‹åˆ†æã€‚")


